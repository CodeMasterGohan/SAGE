# ðŸ§  Developer Internals

A deep dive into SAGE-Docs architecture for contributors and advanced users.

---

## ðŸ“ Project Structure

```
SAGE/
â”œâ”€â”€ ðŸ“„ docker-compose.yml      # Service orchestration
â”œâ”€â”€ ðŸ“„ README.md               # Project overview
â”œâ”€â”€ ðŸ“„ .gitignore              # Git exclusions
â”‚
â”œâ”€â”€ ðŸ“‚ backend/                # FastAPI Dashboard + REST API
â”‚   â”œâ”€â”€ ðŸ“„ Dockerfile          # Container build instructions
â”‚   â”œâ”€â”€ ðŸ“„ requirements.txt    # Python dependencies
â”‚   â”œâ”€â”€ ðŸ“„ server.py           # REST API endpoints (~660 lines)
â”‚   â”œâ”€â”€ ðŸ“„ ingest.py           # Document processing pipeline (~600 lines)
â”‚   â””â”€â”€ ðŸ“‚ static/             # Frontend assets
â”‚       â”œâ”€â”€ ðŸ“„ index.html      # Main dashboard HTML
â”‚       â”œâ”€â”€ ðŸ“„ app.js          # Frontend JavaScript logic
â”‚       â””â”€â”€ ðŸ“„ styles.css      # Custom CSS styles
â”‚
â”œâ”€â”€ ðŸ“‚ mcp-server/             # Model Context Protocol Server
â”‚   â”œâ”€â”€ ðŸ“„ Dockerfile          # Container build instructions
â”‚   â”œâ”€â”€ ðŸ“„ requirements.txt    # Python dependencies
â”‚   â””â”€â”€ ðŸ“„ main.py             # MCP tools implementation (~490 lines)
â”‚
â”œâ”€â”€ ðŸ“‚ uploads/                # Uploaded document storage
â”‚   â””â”€â”€ ðŸ“‚ {library}/          # Organized by library name
â”‚       â””â”€â”€ ðŸ“‚ {version}/      # Then by version
â”‚
â””â”€â”€ ðŸ“‚ docs/                   # This documentation!
```

---

## ðŸ”„ Data Flow Architecture

### Upload Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   POST /api/upload    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User   â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  server  â”‚
â”‚ Browser â”‚                       â”‚   .py    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                                       â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     File Type Detection
            â”‚   ingest.py   â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ detect_file_type()
            â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼           â–¼           â–¼              â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  MD   â”‚  â”‚  HTML  â”‚  â”‚  PDF   â”‚    â”‚   ZIP    â”‚
    â”‚       â”‚  â”‚  â”€â–¶MD  â”‚  â”‚ olmocr â”‚    â”‚ Extract  â”‚
    â””â”€â”€â”€â”¬â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
        â”‚          â”‚           â”‚              â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  split_text_semantic â”‚  Chunking with overlap
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   FastEmbed Dense   â”‚  sentence-transformers/all-MiniLM-L6-v2
              â”‚   FastEmbed BM25    â”‚  Qdrant/bm25
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   Qdrant Upsert     â”‚  Store vectors + metadata
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Search Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   POST /api/search    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User   â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  server  â”‚
â”‚ Browser â”‚                       â”‚   .py    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                                       â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Generate Embeddings  â”‚
        â”‚  â€¢ Dense (semantic)   â”‚
        â”‚  â€¢ Sparse (BM25)      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Qdrant query_points  â”‚
        â”‚  â€¢ Prefetch dense     â”‚
        â”‚  â€¢ Prefetch sparse    â”‚
        â”‚  â€¢ Fusion (DBSF/RRF)  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Format & Return      â”‚
        â”‚  search results       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ”§ Core Components

### Backend Server (`server.py`)

The FastAPI server handles:

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/status` | GET | Health check and Qdrant connection |
| `/api/upload` | POST | Single file upload |
| `/api/upload-multiple` | POST | Batch file upload |
| `/api/upload/async` | POST | Background upload for large files |
| `/api/upload/status/{id}` | GET | Check async upload progress |
| `/api/search` | POST | Hybrid search with fusion |
| `/api/resolve` | POST | Find libraries by name |
| `/api/libraries` | GET | List all libraries |
| `/api/document` | GET | Retrieve full document |
| `/api/library/{name}` | DELETE | Delete library |
| `/` | GET | Serve dashboard HTML |

**Key Classes:**

```python
class SearchRequest(BaseModel):
    query: str
    library: Optional[str] = None
    version: Optional[str] = None
    limit: int = 5
    fusion: str = "dbsf"

class SearchResult(BaseModel):
    content: str
    library: str
    version: str
    title: str
    type: str
    file_path: str
    score: float
```

### Ingestion Pipeline (`ingest.py`)

The document processor handles:

| Function | Purpose |
|----------|---------|
| `detect_file_type()` | Determine format from extension/content |
| `convert_html_to_markdown()` | Clean HTML â†’ Markdown conversion |
| `extract_pdf_text()` | olmocr PDF processing |
| `extract_docx_text()` | Word document extraction |
| `extract_excel_text()` | Excel spreadsheet parsing |
| `split_text_semantic()` | Smart chunking with overlap |
| `ingest_document()` | Main entry point |
| `ensure_collection()` | Create Qdrant collection if missing |

**Chunking Configuration:**

```python
CHUNK_SIZE = 1500      # Characters per chunk
CHUNK_OVERLAP = 200    # Overlap between chunks
```

### MCP Server (`main.py`)

Exposes four tools to LLMs:

| Tool | Description |
|------|-------------|
| `search_docs` | Hybrid search with optional reranking |
| `list_libraries` | O(1) library enumeration via facets |
| `resolve_library` | Fuzzy library name matching |
| `get_document` | Retrieve and reconstruct full document |

**Transport Options:**

```bash
# stdio (for Claude Desktop, Gemini CLI)
python main.py

# HTTP/SSE (for containerized deployment)
python main.py --transport http --port 8000
```

---

## ðŸ’¾ Qdrant Schema

### Collection Configuration

```python
vectors_config={
    "dense": VectorParams(
        size=384,  # MiniLM-L6-v2
        distance=Distance.COSINE
    )
},
sparse_vectors_config={
    "sparse": SparseVectorParams(
        index=SparseIndexParams(on_disk=False)
    )
},
quantization_config=ScalarQuantization(
    scalar=ScalarQuantizationConfig(
        type=ScalarType.INT8,
        always_ram=True
    )
)
```

### Point Payload Structure

Each indexed chunk contains:

```python
{
    "content": str,       # The actual chunk text
    "library": str,       # Library name
    "version": str,       # Version string
    "title": str,         # Document title
    "file_path": str,     # Path to stored file
    "chunk_index": int,   # Position in document
    "total_chunks": int,  # Total chunks in document
    "type": str           # Always "document"
}
```

### Indexes

```python
# Payload indexes for efficient filtering
client.create_payload_index("library", PayloadSchemaType.KEYWORD)
client.create_payload_index("version", PayloadSchemaType.KEYWORD)
client.create_payload_index("file_path", PayloadSchemaType.KEYWORD)
```

---

## ðŸ§ª Custom Scripts

Scripts available in `docker-compose.yml`:

| Command | Description |
|---------|-------------|
| `docker-compose up -d --build` | Build and start all services |
| `docker-compose logs -f backend` | Stream backend logs |
| `docker-compose logs -f mcp-server` | Stream MCP server logs |
| `docker-compose down` | Stop all services |
| `docker-compose down -v` | Stop and remove volumes (âš ï¸ deletes data) |

---

## ðŸ”Œ API Examples

### Search Documents

```bash
curl -X POST http://localhost:8080/api/search \
  -H "Content-Type: application/json" \
  -d '{
    "query": "authentication best practices",
    "library": "react",
    "limit": 5,
    "fusion": "dbsf"
  }'
```

### Upload a Document

```bash
curl -X POST http://localhost:8080/api/upload \
  -F "file=@./docs/guide.md" \
  -F "library=my-library" \
  -F "version=1.0"
```

### List All Libraries

```bash
curl http://localhost:8080/api/libraries
```

### Delete a Library

```bash
curl -X DELETE http://localhost:8080/api/library/my-library
```

---

## ðŸ§© Extending SAGE-Docs

### Adding a New File Format

1. Add detection in `ingest.py`:

```python
def detect_file_type(filename: str, content: bytes) -> str:
    ext = Path(filename).suffix.lower()
    if ext == '.custom':
        return 'custom'
    # ...existing logic
```

2. Add extraction function:

```python
def extract_custom_text(content: bytes) -> str:
    # Your conversion logic here
    return markdown_text
```

3. Wire it into `process_file()`:

```python
def process_file(content, filename, library, version):
    file_type = detect_file_type(filename, content)
    if file_type == 'custom':
        return extract_custom_text(content)
    # ...existing logic
```

### Using a Different Embedding Model

Update `docker-compose.yml`:

```yaml
backend:
  environment:
    - DENSE_MODEL_NAME=nomic-ai/nomic-embed-text-v1.5
    - DENSE_VECTOR_SIZE=768
    - USE_NOMIC_PREFIX=true
```

> âš ï¸ **Warning:** Delete the Qdrant collection first, as dimensions won't match!

---

## ðŸ“Š Performance Considerations

| Component | Bottleneck | Optimization |
|-----------|------------|--------------|
| PDF Processing | olmocr layout analysis | Async upload endpoint |
| Embedding | Model inference | Lazy load, cache models |
| Search | Vector similarity | INT8 quantization |
| BM25 | Index size | In-memory sparse vectors |

### Memory Usage

| Service | Recommended RAM |
|---------|-----------------|
| Backend | 4-6 GB |
| MCP Server | 2-4 GB |
| Qdrant | 1-2 GB (scales with data) |

---

## ðŸ”— Related Resources

- **[ðŸ  Welcome](./00-Welcome.md)** â€” Project overview
- **[ðŸš€ Quick Start](./01-Quick-Start.md)** â€” Get running fast
- **[ðŸ“– User Guide](./02-User-Guide.md)** â€” Feature walkthrough

---

> ðŸ’¡ **Tip:** Found something that could be improved? Contributions are welcome! The codebase is designed to be approachable.
